{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages and paths\n",
    "# %%\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import scipy.stats as sp\n",
    "import sys\n",
    "import zipfile\n",
    "import fiona\n",
    "\n",
    "# Add the path to the Utils folder\n",
    "utils_path = os.path.abspath(os.path.join('..', 'Utils'))\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.append(utils_path)\n",
    "\n",
    "# Now you can import the functions from CustomFunctions.py\n",
    "import CustomFunctions as cf\n",
    "\n",
    "# Local paths\n",
    "datapath = '../../Data'\n",
    "inputpath = '../../Data/Input'\n",
    "outputpath = '../../Data/Output/Local'\n",
    "shapepath = inputpath+'/Shapefiles'\n",
    "figurepath = '../../Figures/Local/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = inputpath+\"/NHD/\"\n",
    "\n",
    "# Don't run this if files are already unzipped\n",
    "\n",
    "# for file in os.listdir(folder_path):\n",
    "#     if file.endswith(\".zip\"):\n",
    "#         with zipfile.ZipFile(os.path.join(folder_path, file), 'r') as zip_ref:\n",
    "#             zip_ref.extractall(folder_path)\n",
    "\n",
    "# print(\"Files unzipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes about 2 minutes max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = \"path_to_your_unzipped_files\"\n",
    "flowline_gdfs = []\n",
    "point_gdfs = []\n",
    "value_added_tables = []\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith(\".gpkg\"):\n",
    "        filepath = os.path.join(folder_path, file)\n",
    "\n",
    "        # Load specific layers\n",
    "        flowlines = gp.read_file(filepath, layer=\"NHDFlowline\")\n",
    "        \n",
    "        # If the value-added table is non-spatial, use pandas instead\n",
    "        value_added = gp.read_file(filepath, layer=\"NHDPlusFlowlineVAA\")  # Change to `pd.read_csv()` if needed\n",
    "\n",
    "        flowline_gdfs.append(flowlines)\n",
    "        value_added_tables.append(value_added)\n",
    "\n",
    "# Merge the layers separately\n",
    "merged_flowlines = gp.GeoDataFrame(pd.concat(flowline_gdfs, ignore_index=True))\n",
    "merged_value_added = pd.concat(value_added_tables, ignore_index=True)  # Non-spatial data\n",
    "\n",
    "# # Save to new files\n",
    "# merged_flowlines.to_file(\"merged_flowlines.gpkg\", driver=\"GPKG\")\n",
    "# merged_value_added.to_csv(\"merged_value_added_table.csv\")  # Save as a CSV if non-spatial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_flowlines.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowlines_VAA = pd.merge(merged_flowlines,merged_value_added,\n",
    "                         suffixes=['_flowlines','_VAA'], how=\"inner\",\n",
    "                         on=['nhdplusid','reachcode'])\n",
    "flowlines_VAA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flowlines_VAA.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I would like to now filter to only include a certain stream order.\n",
    "\n",
    "# Note: This notebook has gotten hefty and Ë†can only publish if this 4+\n",
    "# , but change this to 3 for actual analysis:\n",
    "stream_order = 4 #3\n",
    "filtered_flowlines = flowlines_VAA[flowlines_VAA[\"streamorde\"] >= stream_order]\n",
    "\n",
    "# filtered_flowlines.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_flowlines.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hucnum = '4'\n",
    "filepath = shapepath+'/NHD_H_Arizona_State_Shape/Shape/WBDHU'+hucnum+'.shp'\n",
    "hucs = gp.read_file(filepath)\n",
    "hucs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the crs\n",
    "print(filtered_flowlines.crs)\n",
    "print(hucs.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the databases\n",
    "flowlines_hucs = gp.sjoin(filtered_flowlines, hucs, how=\"inner\")\n",
    "# flowlines_hucs.info()\n",
    "\n",
    "# Takes about 4-7 minutes and if it worked, the same number as non-null values before except now it has a huc# column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowlines_hucs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the Flowlines is ready to go, let's connect the point data (has streamgauge data) to the flowlines record with reach codes and drop the geometry of the point data.\n",
    "\n",
    "This data will be located in a different folder because it was not in the high resolution dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = shapepath+'/NHD_H_Arizona_State_Shape/Shape/NHDPointEventFC.shp'\n",
    "NHD_Point = gp.read_file(filepath)\n",
    "# NHD_Point.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"source_fea\" column has the USGS ID we need in order to connect it to the stream gauge data.\n",
    "\n",
    "Also the reachcode is what connects all this to the flowlines.  So let's first merge the point data to the flowlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowlines_points = pd.merge(flowlines_hucs,NHD_Point,\n",
    "                         suffixes=['_flowlines','_point'], how=\"left\",\n",
    "                         on=['reachcode'])\n",
    "flowlines_points.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flowlines_points.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flowlines_points.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a monster database so maybe make it a little smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_fldb = flowlines_points[['permanent_identifier', 'gnis_name','reachcode','streamorde','source_fea','huc'+hucnum,'name','geometry_flowlines','fcode','hydroseq']]\n",
    "smaller_fldb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_fldb = smaller_fldb.rename(columns = {'geometry_flowlines':'geometry',\n",
    "                                              'name':'huc_name',\n",
    "                                              'source_fea':'ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smaller_fldb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smaller_fldb.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_fldb.to_file(f'{outputpath}/huc{hucnum}flowlines_order{stream_order}plus.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azdroughtanalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
